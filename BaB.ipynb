{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_handler import Data, RF_COL\n",
    "from termcolor import colored\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "Data_instance = Data()               # create instance of the class Data()\n",
    "data = Data_instance.get_data()      # store the data of Data_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['permno','date'],inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Betting Against Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('date').first().sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add excess returns\n",
    "data['Rn_e'] = data['ret'] - data[RF_COL]\n",
    "data['Rm_e'] = data['vwretd'] - data[RF_COL]\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna().copy()\n",
    "\n",
    "# Rolling betas for each stock, based on 5-year windows (code from PS5)\n",
    "w = 5 * 12  # window size\n",
    "covariance = data.set_index('date').groupby('permno')[['Rn_e', 'Rm_e']].rolling(window=w, min_periods=36).cov()\n",
    "betas = covariance.iloc[1::2,1].droplevel(2) / covariance.iloc[0::2,1].droplevel(2)\n",
    "betas = betas.dropna().reset_index().rename(columns={'Rm_e': 'beta'})\n",
    "\n",
    "# Make sure the dates columns are datetime\n",
    "betas.date = pd.to_datetime(betas.date)\n",
    "data.date = pd.to_datetime(data.date)\n",
    "\n",
    "# Offset the dates of the betas by 1 month (code from PS5)\n",
    "betas.date = betas.date + pd.DateOffset(months=1)\n",
    "\n",
    "# Merge the full data with betas (code from PS5)\n",
    "data_Qb = pd.merge(data, betas, on=['permno', 'date'], how='left')\n",
    "\n",
    "# Finally, we winsorize the betas (5% and 95%) (code from PS5)\n",
    "data_Qb['beta'] = data_Qb['beta'].clip(data_Qb['beta'].quantile(0.05), data_Qb['beta'].quantile(0.95))\n",
    "\n",
    "# Drop all nan\n",
    "data_Qb = data_Qb.dropna().copy()\n",
    "\n",
    "print('Distribution of betas:')\n",
    "print(data_Qb['beta'].describe(), '\\n')\n",
    "\n",
    "\n",
    "display(data_Qb.head()) # Overview of the data\n",
    "print(data_Qb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Qb = data.copy().dropna() # Uncomment if decide to use the class method to get the rolling betas, which gives different results 😃\n",
    "print(\"Initial number of observations: \", data.shape[0])\n",
    "print(\"Final number of observations: \\t\", data_Qb.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles based on Beta value (code from PS5)\n",
    "data_Qb[\"EW_monthly_decile\"] = data_Qb.groupby(\"date\")[\"beta\"].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns = data_Qb.groupby([\"date\", \"EW_monthly_decile\"]).agg({\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'EW_monthly_decile': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'EW_monthly_decile': 'decile'})\n",
    "\n",
    "print(\"Equally weighted returns per month, for each decile:\")\n",
    "display(EW_returns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_Qb['VW_weight'] = data_Qb.groupby(['date', 'EW_monthly_decile'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_Qb['VW_ret_contrib'] = data_Qb['VW_weight'] * data_Qb['ret']\n",
    "\n",
    "VW_returns = data_Qb.groupby([\"date\", \"EW_monthly_decile\"]).agg({\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'EW_monthly_decile': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'EW_monthly_decile': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(\"Value weighted returns per month, for each decile:\")\n",
    "display(VW_returns.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean returns, volatility, and sharpe ratios for EW and VW portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_sharpe(data):\n",
    "    \"\"\"Compute the annulalized mean, standard deviation and Sharpe ratio for each decile.\"\"\"\n",
    "    mean = list(map(lambda x: 12*x, data.groupby('decile')['ret'].mean().values.tolist()))\n",
    "    std = list(map(lambda x: np.sqrt(12)*x, data.groupby('decile')['ret'].std().values.tolist()))\n",
    "    rf = np.mean(list(map(lambda x: 12*x, data.groupby('decile')[RF_COL].mean().values.tolist())))\n",
    "    sr = list(map(lambda ret, vol: (ret - rf) / vol, mean, std))\n",
    "    \n",
    "    return mean, std, sr\n",
    "\n",
    "def plot_from_lists(mean, std, sharpe, plot_color = 'blue'):\n",
    "    deciles = list(range(len(mean)))\n",
    "\n",
    "    a, axs = plt.subplots(1, 3, figsize=(25, 7), sharey=False)\n",
    "\n",
    "    axs[0].bar(deciles, mean, color=plot_color)\n",
    "    axs[0].set_title(\"Average portolio mean return\")\n",
    "    axs[0].set_xticks(deciles)\n",
    "    axs[0].set_xlabel(\"Decile\")\n",
    "    axs[0].set_ylabel(\"Annualized return\")\n",
    "\n",
    "    axs[1].bar(deciles, std, color=plot_color)\n",
    "    axs[1].set_title(\"Average portolio annualized standard deviation\")\n",
    "    axs[1].set_xticks(deciles)\n",
    "    axs[1].set_xlabel(\"Decile\")\n",
    "    axs[1].set_ylabel(\"Annualized standard deviation\")\n",
    "\n",
    "    axs[2].bar(deciles, sharpe, color=plot_color)\n",
    "    axs[2].set_title(\"Average portolio annualized sharpe ratio\")\n",
    "    axs[2].set_xticks(deciles)\n",
    "    axs[2].set_xlabel(\"Decile\")\n",
    "    axs[2].set_ylabel(\"Annualized sharpe ratio\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "def plot_mean_std_sr(data, question, plot_name, show = True):\n",
    "    \"\"\"Takes a dataframe in input and returns a 3 graphs for the  annualized mean, std and sharpe ratio for some deciles.\"\"\"\n",
    "\n",
    "    if not os.path.exists(\"Figures\"):\n",
    "            os.makedirs(\"Figures\")\n",
    "    \n",
    "    mean, std, sharpe = get_mean_std_sharpe(data)\n",
    "\n",
    "    plot = plot_from_lists(mean, std, sharpe, plot_color = 'blue')\n",
    "\n",
    "    if show:\n",
    "        plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio ({plot_name})')\n",
    "        plot.savefig(f\"Figures/question_{question}_plot_{plot_name}\")\n",
    "        plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns, '3b', \"EW_returns_BAB\")\n",
    "plot_mean_std_sr(VW_returns, '3b', \"VW_returns_BAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c) and d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built the function for determining BAB weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bab_weights(data):\n",
    "    \"\"\"Computes the weights of the Betting-Against-Beta portfolio (code inspired from PS5).\"\"\"\n",
    "    df = data.copy()\n",
    "    df['z'] = df.groupby('date')['beta'].rank()                     # Assign each beta a rank, for each month\n",
    "    df['z_mean'] = df.groupby('date')['z'].transform('mean')        # Calculate the monthly mean the rank\n",
    "    df['norm'] = np.abs(df['z']- df['z_mean'])                      # Compute abs distance of rank to mean rank\n",
    "    df['sum_norm'] = df.groupby('date')['norm'].transform(\"sum\")    # Sum the distance\n",
    "    df['k'] = 2 / df['sum_norm']                                    # Compute the k\n",
    "\n",
    "    # Compute the BAB weights\n",
    "    df['wH'] = df['k'] * np.maximum(0, df['z'] - df['z_mean'])\n",
    "    df['wL'] = - df['k'] * np.minimum(0, df['z'] - df['z_mean'])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(columns=[\"z_mean\", 'z', 'norm', 'sum_norm', 'k'])\n",
    "\n",
    "    # Compute the weighted betas\n",
    "    df['bH'] = df['wH'] * df['beta']\n",
    "    df['bL'] = df['wL'] * df['beta']\n",
    "\n",
    "    # Compute the individual excess returns of the portfolios H and L\n",
    "    df['rH_e'] = df['wH'] * (df['ret'] - df[RF_COL])\n",
    "    df['rL_e'] = df['wL'] * (df['ret'] - df[RF_COL]) # Check that crazy formula bby 😃  (en gros, c'est okay de faire weight * excess return au lieu de faire weight * excess return?)\n",
    "    \n",
    "    # Compute the return and betas of the two portfolios for each period\n",
    "    df_ = df.groupby('date').agg({\n",
    "        'rH_e': 'sum',\n",
    "        'rL_e': 'sum',\n",
    "        'bH': 'sum',\n",
    "        'bL': 'sum',\n",
    "        'Rm_e': 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "    # Finally create the BAB portfolio return\n",
    "    df_['rBAB'] = df_['rL_e'] / df_['bL'] - df_['rH_e'] / df_['bH']\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights rBAB\n",
    "data_BAB = get_bab_weights(data_Qb)\n",
    "display(data_BAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the return, std and sharpe ratio of the BAB strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the rf based on question b) results, as the underlying data is the same\n",
    "rf = np.mean(list(map(lambda x: 12*x, VW_returns.groupby('decile')[RF_COL].mean().values.tolist())))\n",
    "\n",
    "# Compute the return, std and Sharpe ratio of the BAB strategy\n",
    "BAB_ret = data_BAB.rBAB.mean() * 12\n",
    "BAB_std = data_BAB.rBAB.std() * np.sqrt(12)\n",
    "BAB_shr = (BAB_ret - rf) / BAB_std\n",
    "\n",
    "# Compute the CAPM alpha\n",
    "data_BAB['one'] = 1 # Create the column for the constant\n",
    "model = sm.OLS(data_BAB['rBAB'], data_BAB[['one', 'Rm_e']]).fit() # Fit CAPM\n",
    "\n",
    "print(colored(\"Betting-against-beta strategy\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Mean return: {:.2f}\".format(BAB_ret))\n",
    "print(\" - Standard deviation: {:.2f}\".format(BAB_std))\n",
    "print(\" - Sharpe ratio: {:.2f}\".format(BAB_shr))\n",
    "print(\" - CAPM alpha: {:.2f}\".format(model.params.iloc[0] * 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Momentum Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the deciles based on the 12-month cumulative return, excluding short term reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['permno', 'date'], inplace=True)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by permno, then date\n",
    "data_mom = data.copy()\n",
    "data_mom.sort_values(by=['permno', 'date'], inplace=True)\n",
    "\n",
    "# Add a column for momentum return (last 12 months, excluding last month)\n",
    "data_mom['roll_ret'] = data_mom.groupby('permno').ret.transform(lambda x: x.rolling(11, closed='left').sum())\n",
    "display(data_mom.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles for the momentum returns\n",
    "data_mom['decile_mom'] = data_mom.groupby('date')['roll_ret'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Compute the monthly return for each decile (this is the average of the individual monthly return of each stock from each decile)\n",
    "data_mom['EW_monthly_return'] = data_mom.groupby(['date', 'decile_mom'])['ret'].transform('mean')\n",
    "\n",
    "# Drop nan values\n",
    "data_mom = data_mom.dropna().copy()\n",
    "\n",
    "display(data_mom.head())\n",
    "print(data_mom.shape)\n",
    "# data_mom.to_csv('data_mom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns_mom = data_mom.groupby(['date', 'decile_mom']).agg({\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'decile_mom': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'decile_mom': 'decile'})\n",
    "\n",
    "print(colored(\"Equally weighted returns per month, for each decile:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(EW_returns_mom.head(5))\n",
    "print(EW_returns_mom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_mom['VW_weight'] = data_mom.groupby(['date', 'decile_mom'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_mom['VW_ret_contrib'] = data_mom['VW_weight'] * data_mom['ret']\n",
    "\n",
    "VW_returns_mom = data_mom.groupby([\"date\", \"decile_mom\"]).agg({\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'decile_mom': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'decile_mom': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(colored(\"Value weighted returns per month, for each decile:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(VW_returns_mom.head(5))\n",
    "print(VW_returns_mom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns_mom, '4a', \"EW_returns_MOM\")\n",
    "plot_mean_std_sr(VW_returns_mom, '4a', \"VW_returns_MOM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column 'leg' that is 1 if the decile is 7, 8 or 9, and -1 if decile is 0, 1, 2\n",
    "data_mom['leg'] = np.nan\n",
    "data_mom.loc[data_mom['decile_mom'] <= 2, 'leg'] = -1\n",
    "data_mom.loc[data_mom['decile_mom'] >= 7, 'leg'] = 1\n",
    "\n",
    "# Drop the observations that are in none of the legs\n",
    "data_mom_b = data_mom.dropna().copy()\n",
    "display(data_mom_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that aggregates takes the average return for each leg, at each month. Also keep the risk free rate\n",
    "EW_data_mom = data_mom_b.groupby(['date', 'leg']).agg({\n",
    "    'ret': 'mean', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "EW_data_mom_piv = EW_data_mom.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "EW_data_mom_piv['EW_return'] = EW_data_mom_piv[1] - EW_data_mom_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "EW_data_mom_piv[RF_COL] = EW_data_mom.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "EW_data_mom_piv = EW_data_mom_piv[['EW_return', RF_COL]]   # Keep only the relevant columns\n",
    "# display(EW_data_mom_piv)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean = EW_data_mom_piv['EW_return'].mean() * 12\n",
    "std = EW_data_mom_piv['EW_return'].std() * np.sqrt(12)\n",
    "rf = EW_data_mom_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on equally weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}%\".format(mean))\n",
    "print(\" - Standard deviation:\\t {:.2f}%\".format(std))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean - rf)/ std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "###  Value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VW_data_mom = data_mom_b.copy()\n",
    "\n",
    "VW_data_mom['VW_wL'] = (VW_data_mom['leg'] == -1) * VW_data_mom['mcap']\n",
    "VW_data_mom['VW_wL_sum'] = VW_data_mom.groupby('date')['VW_wL'].transform('sum')\n",
    "VW_data_mom['VW_wH'] = (VW_data_mom['leg'] == 1) * VW_data_mom['mcap']\n",
    "VW_data_mom['VW_wH_sum'] = VW_data_mom.groupby('date')['VW_wH'].transform('sum')\n",
    "VW_data_mom['VW_wL'] = VW_data_mom['VW_wL'] / VW_data_mom['VW_wL_sum']\n",
    "VW_data_mom['VW_wH'] = VW_data_mom['VW_wH'] / VW_data_mom['VW_wH_sum']\n",
    "VW_data_mom = VW_data_mom.drop(columns=['VW_wL_sum', 'VW_wH_sum'])\n",
    "VW_data_mom['VW_w'] = VW_data_mom['VW_wL'] * VW_data_mom['leg'] + VW_data_mom['VW_wH'] * VW_data_mom['leg']\n",
    "VW_data_mom['VW_ret'] = VW_data_mom['VW_w'] * VW_data_mom['ret']\n",
    "\n",
    "\n",
    "# Create a dataframe that aggregates the returns, at each month and keep the risk free rate\n",
    "VW_data_mom_ = VW_data_mom.groupby(['date']).agg({\n",
    "    'VW_ret': 'sum', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "# display(VW_data_mom_)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean = VW_data_mom_['VW_ret'].mean() * 12\n",
    "std = VW_data_mom_['VW_ret'].std() * np.sqrt(12)\n",
    "rf = VW_data_mom_[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on value weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}%\".format(mean))\n",
    "print(\" - Standard deviation:\\t {:.2f}%\".format(std))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean - rf)/ std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Idiosyncratic Volatility Strategy (IV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iv = data_Qb.drop(columns=['VW_weight', 'VW_ret_contrib', 'mcap_l', 'EW_monthly_decile']).copy()\n",
    "display(data_iv.head())\n",
    "print(data_iv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use previously computed rolling betas to compute the residuals of the regression of the stock's excess return against market excess return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️ Je suis pas sur que ce soit la bonne manière puisque les betas sont calculés sur une rolling window déjà, mais on recalcule l'écart type des résidus sur une rolling window (rolling de rolling??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residuals\n",
    "data_iv['residuals'] = data_iv['Rn_e'] - (data_iv['beta'] * data_iv['Rm_e'])\n",
    "\n",
    "# Compute volatility of residuals (idiosyncratic volatility)\n",
    "data_iv['IV'] = data_iv.groupby('permno')['residuals'].rolling(window=w, min_periods=36).std().reset_index(level=0, drop=True)\n",
    "data_iv = data_iv.dropna(subset=['IV']).copy()\n",
    "\n",
    "# Winsorize at 5% and 95% (code from PS5)\n",
    "data_iv['IV'] = data_iv['IV'].clip(data_iv['IV'].quantile(0.05), data_iv['IV'].quantile(0.95))\n",
    "\n",
    "data_iv = data_iv.drop(columns=['residuals']) # no need that column anymore\n",
    "\n",
    "display(data_iv.head())\n",
    "print(data_iv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles based on IV\n",
    "data_iv[\"IV_decile\"] = data_iv.groupby(\"date\")[\"IV\"].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns_IV = data_iv.groupby([\"date\", \"IV_decile\"]).agg({\n",
    "    'date': 'first',\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'IV_decile': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'IV_decile': 'decile'})\n",
    "\n",
    "print(colored(\"Equally weighted monthly returns per decile, IV:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(EW_returns_IV.head(5))\n",
    "print(EW_returns_IV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_iv['VW_weight'] = data_iv.groupby(['date', 'IV_decile'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_iv['VW_ret_contrib'] = data_iv['VW_weight'] * data_iv['ret']\n",
    "\n",
    "VW_returns_IV = data_iv.groupby([\"date\", \"IV_decile\"]).agg({\n",
    "    'date': 'first',\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'IV_decile': 'first',\n",
    "    }).reset_index(drop=True).rename(columns={'IV_decile': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(colored(\"Value weighted monthly returns per decile, IV:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(VW_returns_IV.head(5))\n",
    "print(VW_returns_IV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean, std, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns_IV, '5b', \"EW_returns_IV\")\n",
    "plot_mean_std_sr(VW_returns_IV, '5b', \"VW_returns_IV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column 'leg' that is 1 if the decile is 7, 8 or 9, and -1 if decile is 0, 1, 2\n",
    "data_iv['leg'] = np.nan\n",
    "data_iv.loc[data_iv['IV_decile'] <= 2, 'leg'] = -1\n",
    "data_iv.loc[data_iv['IV_decile'] >= 7, 'leg'] = 1\n",
    "\n",
    "# Drop the observations that are in none of the legs\n",
    "data_iv_c = data_iv.dropna().copy()\n",
    "\n",
    "display(data_iv_c.head())\n",
    "print(data_iv_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compare the performance of each leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of each leg\n",
    "EW_returns_IV_legs = data_iv_c.groupby([\"date\", \"leg\"]).agg({\n",
    "    'date': 'first',\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'leg': 'first'\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "testons = EW_returns_IV_legs.groupby('leg').agg({\n",
    "    'ret': 'std',\n",
    "    RF_COL: 'mean'\n",
    "    }).reset_index()\n",
    "display(testons)\n",
    "\n",
    "print(colored(\"Equally weighted monthly returns per leg, IV:\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\"Leg =  1 if decile is 7, 8, 9 \\nLeg = -1 if decile is 0, 1, 2\")\n",
    "display(EW_returns_IV_legs.head(5))\n",
    "print(EW_returns_IV_legs.shape)\n",
    "\n",
    "# Plot the mean, std, sr\n",
    "plot_mean_std_sr(EW_returns_IV_legs.rename(columns={'leg': 'decile'}), '5c', \"EW_returns_IV_legs\")\n",
    "print(\"In the graph, leg '-1' corresponds to bar '0'; leg '1' is bar '1'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, display the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that aggregates takes the average return for each leg, at each month. Also keep the risk free rate\n",
    "EW_data_IV_leg = data_iv_c.groupby(['date', 'leg']).agg({\n",
    "    'ret': 'mean', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "EW_data_IV_piv = EW_data_IV_leg.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "EW_data_IV_piv['EW_return'] = EW_data_IV_piv[1] - EW_data_IV_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "EW_data_IV_piv[RF_COL] = EW_data_IV_leg.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "EW_data_IV_piv = EW_data_IV_piv[['EW_return', RF_COL]]   # Keep only the relevant columns\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean_EW_IV = EW_data_IV_piv['EW_return'].mean() * 12\n",
    "std_EW_IV = EW_data_IV_piv['EW_return'].std() * np.sqrt(12)\n",
    "rf_EW_IV = EW_data_IV_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on equally weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}\".format(mean_EW_IV))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(std_EW_IV))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean_EW_IV - rf_EW_IV)/ std_EW_IV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the 2 legs and the strategy in a graph\n",
    "mean, std, sr = get_mean_std_sharpe(EW_returns_IV_legs.rename(columns={'leg': 'decile'}))\n",
    "mean.append(mean_EW_IV), std.append(std_EW_IV), sr.append((mean_EW_IV - rf_EW_IV)/ std_EW_IV)\n",
    "# print(mean, std, sr)\n",
    "\n",
    "plot = plot_from_lists(mean, std, sr, plot_color = 'blue')\n",
    "\n",
    "plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio (EW_IV_legs_strat)')\n",
    "plot.savefig(f\"Figures/question_5c_plot_EW_IV_legs_strat\")\n",
    "plot.show()\n",
    "print(\"Bar 0: leg -1; Bar 1: leg 1; Bar 2: Strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compare the performance of each leg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-use the dataframe from earlier question, we already computed the VW contribution\n",
    "VW_data_IV = data_iv_c.copy()\n",
    "\n",
    "VW_returns_IV_legs = VW_data_IV.groupby(['date', 'leg']).agg({\n",
    "    'VW_ret_contrib': 'sum', \n",
    "    RF_COL: 'first',\n",
    "    }).rename(columns={'VW_ret_contrib': 'ret'}).reset_index()\n",
    "\n",
    "display(VW_returns_IV_legs)\n",
    "\n",
    "# Plot the mean, std, sr\n",
    "plot_mean_std_sr(VW_returns_IV_legs.rename(columns={'leg': 'decile'}), '5c', \"VW_returns_IV_legs\")\n",
    "print(\"In the graph, leg '-1' corresponds to bar '0'; leg '1' is bar '1'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the same methodolgy as before to compute the return of the strategy\n",
    "VW_data_IV_piv = VW_returns_IV_legs.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "VW_data_IV_piv['VW_return'] = VW_data_IV_piv[1] - VW_data_IV_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "VW_data_IV_piv[RF_COL] = VW_data_IV_leg.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "VW_data_IV_piv = VW_data_IV_piv[['VW_return', RF_COL]]   # Keep only the relevant columns\n",
    "display(VW_data_IV_piv)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean_VW_IV = VW_data_IV_piv['VW_return'].mean() * 12\n",
    "std_VW_IV = VW_data_IV_piv['VW_return'].std() * np.sqrt(12)\n",
    "rf_VW_IV = VW_data_IV_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on value weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}\".format(mean_VW_IV))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(std_VW_IV))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean_VW_IV - rf_VW_IV)/ std_VW_IV))\n",
    "\n",
    "# Compare the 2 legs and the strategy in a graph\n",
    "mean, std, sr = get_mean_std_sharpe(VW_returns_IV_legs.rename(columns={'leg': 'decile'}))\n",
    "mean.append(mean_VW_IV), std.append(std_VW_IV), sr.append((mean_VW_IV - rf_VW_IV)/ std_VW_IV)\n",
    "# print(mean, std, sr)\n",
    "\n",
    "plot = plot_from_lists(mean, std, sr, plot_color = 'blue')\n",
    "\n",
    "plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio (VW_IV_legs_strat)')\n",
    "plot.savefig(f\"Figures/question_5c_plot_VW_IV_legs_strat\")\n",
    "plot.show()\n",
    "print(\"Bar 0: leg -1; Bar 1: leg 1; Bar 2: Strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Optimal Fund Portfolio Return (STRAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider the value weighted portfolios from the previous strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOL_TARGET = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we prepare the data\n",
    "dataBAB = data_BAB[['date', 'rBAB']].copy()\n",
    "dataMOM = VW_data_mom_[['date', 'VW_ret', RF_COL]].rename(columns={'VW_ret':'rMOM'}).copy()\n",
    "dataIV = VW_data_IV_piv.rename(columns={'VW_return':'rIV'}).copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "dataSTRAT = pd.merge(dataBAB, dataMOM, on='date', how='inner')\n",
    "dataSTRAT = pd.merge(dataSTRAT, dataIV[['date', 'rIV']], on='date', how='inner')\n",
    "dataSTRAT= dataSTRAT[['date', RF_COL, 'rBAB', 'rMOM', 'rIV']]\n",
    "display(dataSTRAT.head())\n",
    "print(dataSTRAT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the mean, std and Sharpe ratio of the STRAT strategies\n",
    "def get_mean_std_sharpe_STRAT(data, return_col:str):\n",
    "    mean = data[return_col].mean() * 12\n",
    "    std = data[return_col].std() * np.sqrt(12)\n",
    "    rf = data[RF_COL].mean() * 12\n",
    "    sr = (mean - rf) / std\n",
    "    return mean, std, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal weight strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return of STRAT is the the weighted average of the returns of the 3 strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the STRAT return\n",
    "dataSTRAT_EW = dataSTRAT.copy()\n",
    "dataSTRAT_EW['rSTRAT_EW'] = (dataSTRAT_EW['rBAB'] + dataSTRAT_EW['rMOM'] + dataSTRAT_EW['rIV']) / 3\n",
    "dataSTRAT_EW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining the c constant for each year\n",
    "dataSTRAT_EW['rSTRATstd'] = dataSTRAT_EW.groupby(dataSTRAT_EW.date.dt.year)['rSTRAT_EW'].transform('std') * np.sqrt(12)\n",
    "dataSTRAT_EW['C'] = 0.1 / dataSTRAT_EW['rSTRATstd']\n",
    "dataSTRAT_EW['rFUND_EW'] = dataSTRAT_EW['C'] * dataSTRAT_EW['rSTRAT_EW'] + dataSTRAT_EW[RF_COL]\n",
    "\n",
    "display(dataSTRAT_EW.head())\n",
    "print(dataSTRAT_EW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retSTRAT_EW, stdSTRAT_EW, srSTRAT_EW = get_mean_std_sharpe_STRAT(dataSTRAT_EW, 'rFUND_EW')\n",
    "\n",
    "print(colored(\"STRAT strategy based on equally weighted portfolios\", attrs=['underline', 'bold'])) \n",
    "print(\" - Expected return:\\t {:.2f}\".format(retSTRAT_EW))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(stdSTRAT_EW))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format(srSTRAT_EW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-parity based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the weights of BAB, MOM, IV under a risk parity approach, based on the rolling estimate of their return std over the last 36 months (excluding last)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the risk parity, we use the rolling 3-year monthly volatility\n",
    "dataSTRAT_RP = dataSTRAT.copy()\n",
    "\n",
    "dataSTRAT_RP['rBABstd'] = dataSTRAT_RP['rBAB'].rolling(window=36, min_periods=36, closed='left').std() * np.sqrt(12)\n",
    "dataSTRAT_RP['rMOMstd'] = dataSTRAT_RP['rMOM'].rolling(window=36, min_periods=36, closed='left').std() * np.sqrt(12)\n",
    "dataSTRAT_RP['rIVstd'] = dataSTRAT_RP['rIV'].rolling(window=36, min_periods=36, closed='left').std()   * np.sqrt(12)\n",
    "dataSTRAT_RP.dropna(inplace=True)\n",
    "\n",
    "dataSTRAT_RP['rSTRAT'] = dataSTRAT_RP['rBAB']/dataSTRAT_RP['rBABstd'] + dataSTRAT_RP['rMOM']/dataSTRAT_RP['rMOMstd'] + dataSTRAT_RP['rIV']/dataSTRAT_RP['rIVstd']\n",
    "\n",
    "dataSTRAT_RP['rSTRATstd'] = dataSTRAT_RP.groupby(dataSTRAT_RP.date.dt.year)['rSTRAT'].transform('std') * np.sqrt(12)\n",
    "dataSTRAT_RP['C'] = 0.1 / dataSTRAT_RP['rSTRATstd']\n",
    "dataSTRAT_RP['rFUND_EW'] = dataSTRAT_RP['C'] * dataSTRAT_RP['rSTRAT'] + dataSTRAT_RP[RF_COL]\n",
    "\n",
    "retSTRAT_RP, stdSTRAT_RP, srSTRAT_RP = get_mean_std_sharpe_STRAT(dataSTRAT_RP, 'rFUND_EW')\n",
    "\n",
    "print(colored(\"STRAT strategy based on equally risk parity portfolios\", attrs=['underline', 'bold'])) \n",
    "print(\" - Expected return:\\t {:.2f}\".format(retSTRAT_RP))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(stdSTRAT_RP))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format(srSTRAT_RP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
