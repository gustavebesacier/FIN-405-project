{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_handler import Data, RF_COL\n",
    "from termcolor import colored\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "Data_instance = Data()               # create instance of the class Data()\n",
    "data = Data_instance.get_data()      # store the data of Data_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['permno','date'],inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Betting Against Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('date').first().sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add excess returns\n",
    "data['Rn_e'] = data['ret'] - data[RF_COL]\n",
    "data['Rm_e'] = data['vwretd'] - data[RF_COL]\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna().copy()\n",
    "\n",
    "# Rolling betas for each stock, based on 5-year windows (code from PS5)\n",
    "w = 5 * 12  # window size\n",
    "covariance = data.set_index('date').groupby('permno')[['Rn_e', 'Rm_e']].rolling(window=w, min_periods=36).cov()\n",
    "betas = covariance.iloc[1::2,1].droplevel(2) / covariance.iloc[0::2,1].droplevel(2)\n",
    "betas = betas.dropna().reset_index().rename(columns={'Rm_e': 'beta'})\n",
    "\n",
    "# Make sure the dates columns are datetime\n",
    "betas.date = pd.to_datetime(betas.date)\n",
    "data.date = pd.to_datetime(data.date)\n",
    "\n",
    "# Offset the dates of the betas by 1 month (code from PS5)\n",
    "betas.date = betas.date + pd.DateOffset(months=1)\n",
    "\n",
    "# Merge the full data with betas (code from PS5)\n",
    "data_Qb = pd.merge(data, betas, on=['permno', 'date'], how='left')\n",
    "\n",
    "# Finally, we winsorize the betas (5% and 95%) (code from PS5)\n",
    "data_Qb['beta'] = data_Qb['beta'].clip(data_Qb['beta'].quantile(0.05), data_Qb['beta'].quantile(0.95))\n",
    "\n",
    "# Drop all nan\n",
    "data_Qb = data_Qb.dropna().copy()\n",
    "\n",
    "print('Distribution of betas:')\n",
    "print(data_Qb['beta'].describe(), '\\n')\n",
    "\n",
    "\n",
    "display(data_Qb.head()) # Overview of the data\n",
    "print(data_Qb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Qb = data.copy().dropna() # Uncomment if decide to use the class method to get the rolling betas, which gives different results üòÉ\n",
    "print(\"Initial number of observations: \", data.shape[0])\n",
    "print(\"Final number of observations: \\t\", data_Qb.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles based on Beta value (code from PS5)\n",
    "data_Qb[\"EW_monthly_decile\"] = data_Qb.groupby(\"date\")[\"beta\"].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns = data_Qb.groupby([\"date\", \"EW_monthly_decile\"]).agg({\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'EW_monthly_decile': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'EW_monthly_decile': 'decile'})\n",
    "\n",
    "print(\"Equally weighted returns per month, for each decile:\")\n",
    "display(EW_returns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_Qb['VW_weight'] = data_Qb.groupby(['date', 'EW_monthly_decile'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_Qb['VW_ret_contrib'] = data_Qb['VW_weight'] * data_Qb['ret']\n",
    "\n",
    "VW_returns = data_Qb.groupby([\"date\", \"EW_monthly_decile\"]).agg({\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'EW_monthly_decile': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'EW_monthly_decile': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(\"Value weighted returns per month, for each decile:\")\n",
    "display(VW_returns.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean returns, volatility, and sharpe ratios for EW and VW portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_sharpe(data):\n",
    "    \"\"\"Compute the annulalized mean, standard deviation and Sharpe ratio for each decile.\"\"\"\n",
    "    mean = list(map(lambda x: 12*x, data.groupby('decile')['ret'].mean().values.tolist()))\n",
    "    std = list(map(lambda x: np.sqrt(12)*x, data.groupby('decile')['ret'].std().values.tolist()))\n",
    "    rf = np.mean(list(map(lambda x: 12*x, data.groupby('decile')[RF_COL].mean().values.tolist())))\n",
    "    sr = list(map(lambda ret, vol: (ret - rf) / vol, mean, std))\n",
    "    \n",
    "    return mean, std, sr\n",
    "\n",
    "def plot_from_lists(mean, std, sharpe, plot_color = 'blue'):\n",
    "    deciles = list(range(len(mean)))\n",
    "\n",
    "    a, axs = plt.subplots(1, 3, figsize=(25, 7), sharey=False)\n",
    "\n",
    "    axs[0].bar(deciles, mean, color=plot_color)\n",
    "    axs[0].set_title(\"Average portolio mean return\")\n",
    "    axs[0].set_xticks(deciles)\n",
    "    axs[0].set_xlabel(\"Decile\")\n",
    "    axs[0].set_ylabel(\"Annualized return\")\n",
    "\n",
    "    axs[1].bar(deciles, std, color=plot_color)\n",
    "    axs[1].set_title(\"Average portolio annualized standard deviation\")\n",
    "    axs[1].set_xticks(deciles)\n",
    "    axs[1].set_xlabel(\"Decile\")\n",
    "    axs[1].set_ylabel(\"Annualized standard deviation\")\n",
    "\n",
    "    axs[2].bar(deciles, sharpe, color=plot_color)\n",
    "    axs[2].set_title(\"Average portolio annualized sharpe ratio\")\n",
    "    axs[2].set_xticks(deciles)\n",
    "    axs[2].set_xlabel(\"Decile\")\n",
    "    axs[2].set_ylabel(\"Annualized sharpe ratio\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "def plot_mean_std_sr(data, question, plot_name, show = True):\n",
    "    \"\"\"Takes a dataframe in input and returns a 3 graphs for the  annualized mean, std and sharpe ratio for some deciles.\"\"\"\n",
    "\n",
    "    if not os.path.exists(\"Figures\"):\n",
    "            os.makedirs(\"Figures\")\n",
    "    \n",
    "    mean, std, sharpe = get_mean_std_sharpe(data)\n",
    "\n",
    "    plot = plot_from_lists(mean, std, sharpe, plot_color = 'blue')\n",
    "\n",
    "    if show:\n",
    "        plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio ({plot_name})')\n",
    "        plot.savefig(f\"Figures/question_{question}_plot_{plot_name}\")\n",
    "        plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns, '3b', \"EW_returns_BAB\")\n",
    "plot_mean_std_sr(VW_returns, '3b', \"VW_returns_BAB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c) and d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built the function for determining BAB weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bab_weights(data):\n",
    "    \"\"\"Computes the weights of the Betting-Against-Beta portfolio (code inspired from PS5).\"\"\"\n",
    "    df = data.copy()\n",
    "    df['z'] = df.groupby('date')['beta'].rank()                     # Assign each beta a rank, for each month\n",
    "    df['z_mean'] = df.groupby('date')['z'].transform('mean')        # Calculate the monthly mean the rank\n",
    "    df['norm'] = np.abs(df['z']- df['z_mean'])                      # Compute abs distance of rank to mean rank\n",
    "    df['sum_norm'] = df.groupby('date')['norm'].transform(\"sum\")    # Sum the distance\n",
    "    df['k'] = 2 / df['sum_norm']                                    # Compute the k\n",
    "\n",
    "    # Compute the BAB weights\n",
    "    df['wH'] = df['k'] * np.maximum(0, df['z'] - df['z_mean'])\n",
    "    df['wL'] = - df['k'] * np.minimum(0, df['z'] - df['z_mean'])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(columns=[\"z_mean\", 'z', 'norm', 'sum_norm', 'k'])\n",
    "\n",
    "    # Compute the weighted betas\n",
    "    df['bH'] = df['wH'] * df['beta']\n",
    "    df['bL'] = df['wL'] * df['beta']\n",
    "\n",
    "    # Compute the individual excess returns of the portfolios H and L\n",
    "    df['rH_e'] = df['wH'] * (df['ret'] - df[RF_COL])\n",
    "    df['rL_e'] = df['wL'] * (df['ret'] - df[RF_COL]) # Check that crazy formula bby üòÉ  (en gros, c'est okay de faire weight * excess return au lieu de faire weight * excess return?)\n",
    "    \n",
    "    # Compute the return and betas of the two portfolios for each period\n",
    "    df_ = df.groupby('date').agg({\n",
    "        'rH_e': 'sum',\n",
    "        'rL_e': 'sum',\n",
    "        'bH': 'sum',\n",
    "        'bL': 'sum',\n",
    "        'Rm_e': 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "    # Finally create the BAB portfolio return\n",
    "    df_['rBAB'] = df_['rL_e'] / df_['bL'] - df_['rH_e'] / df_['bH']\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights rBAB\n",
    "data_BAB = get_bab_weights(data_Qb)\n",
    "display(data_BAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the return, std and sharpe ratio of the BAB strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the rf based on question b) results, as the underlying data is the same\n",
    "rf = np.mean(list(map(lambda x: 12*x, VW_returns.groupby('decile')[RF_COL].mean().values.tolist())))\n",
    "\n",
    "# Compute the return, std and Sharpe ratio of the BAB strategy\n",
    "BAB_ret = data_BAB.rBAB.mean() * 12\n",
    "BAB_std = data_BAB.rBAB.std() * np.sqrt(12)\n",
    "BAB_shr = (BAB_ret - rf) / BAB_std\n",
    "\n",
    "# Compute the CAPM alpha\n",
    "data_BAB['one'] = 1 # Create the column for the constant\n",
    "model = sm.OLS(data_BAB['rBAB'], data_BAB[['one', 'Rm_e']]).fit() # Fit CAPM\n",
    "\n",
    "print(colored(\"Betting-against-beta strategy\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Mean return: {:.2f}\".format(BAB_ret))\n",
    "print(\" - Standard deviation: {:.2f}\".format(BAB_std))\n",
    "print(\" - Sharpe ratio: {:.2f}\".format(BAB_shr))\n",
    "print(\" - CAPM alpha: {:.2f}\".format(model.params.iloc[0] * 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Momentum Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the deciles based on the 12-month cumulative return, excluding short term reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['permno', 'date'], inplace=True)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by permno, then date\n",
    "data_mom = data.copy()\n",
    "data_mom.sort_values(by=['permno', 'date'], inplace=True)\n",
    "\n",
    "# Add a column for momentum return (last 12 months, excluding last month)\n",
    "data_mom['roll_ret'] = data_mom.groupby('permno').ret.transform(lambda x: x.rolling(11, closed='left').sum())\n",
    "display(data_mom.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles for the momentum returns\n",
    "data_mom['decile_mom'] = data_mom.groupby('date')['roll_ret'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Compute the monthly return for each decile (this is the average of the individual monthly return of each stock from each decile)\n",
    "data_mom['EW_monthly_return'] = data_mom.groupby(['date', 'decile_mom'])['ret'].transform('mean')\n",
    "\n",
    "# Drop nan values\n",
    "data_mom = data_mom.dropna().copy()\n",
    "\n",
    "display(data_mom.head())\n",
    "print(data_mom.shape)\n",
    "# data_mom.to_csv('data_mom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns_mom = data_mom.groupby(['date', 'decile_mom']).agg({\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'decile_mom': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'decile_mom': 'decile'})\n",
    "\n",
    "print(colored(\"Equally weighted returns per month, for each decile:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(EW_returns_mom.head(5))\n",
    "print(EW_returns_mom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_mom['VW_weight'] = data_mom.groupby(['date', 'decile_mom'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_mom['VW_ret_contrib'] = data_mom['VW_weight'] * data_mom['ret']\n",
    "\n",
    "VW_returns_mom = data_mom.groupby([\"date\", \"decile_mom\"]).agg({\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'decile_mom': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'decile_mom': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(colored(\"Value weighted returns per month, for each decile:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(VW_returns_mom.head(5))\n",
    "print(VW_returns_mom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns_mom, '4a', \"EW_returns_MOM\")\n",
    "plot_mean_std_sr(VW_returns_mom, '4a', \"VW_returns_MOM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column 'leg' that is 1 if the decile is 7, 8 or 9, and -1 if decile is 0, 1, 2\n",
    "data_mom['leg'] = np.nan\n",
    "data_mom.loc[data_mom['decile_mom'] <= 2, 'leg'] = -1\n",
    "data_mom.loc[data_mom['decile_mom'] >= 7, 'leg'] = 1\n",
    "\n",
    "# Drop the observations that are in none of the legs\n",
    "data_mom_b = data_mom.dropna().copy()\n",
    "display(data_mom_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that aggregates takes the average return for each leg, at each month. Also keep the risk free rate\n",
    "EW_data_mom = data_mom_b.groupby(['date', 'leg']).agg({\n",
    "    'ret': 'mean', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "EW_data_mom_piv = EW_data_mom.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "EW_data_mom_piv['EW_return'] = EW_data_mom_piv[1] - EW_data_mom_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "EW_data_mom_piv[RF_COL] = EW_data_mom.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "EW_data_mom_piv = EW_data_mom_piv[['EW_return', RF_COL]]   # Keep only the relevant columns\n",
    "#¬†display(EW_data_mom_piv)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean = EW_data_mom_piv['EW_return'].mean() * 12\n",
    "std = EW_data_mom_piv['EW_return'].std() * np.sqrt(12)\n",
    "rf = EW_data_mom_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on equally weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}%\".format(mean))\n",
    "print(\" - Standard deviation:\\t {:.2f}%\".format(std))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean - rf)/ std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "###  Value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VW_data_mom = data_mom_b.copy()\n",
    "\n",
    "VW_data_mom['VW_wL'] = (VW_data_mom['leg'] == -1) * VW_data_mom['mcap']\n",
    "VW_data_mom['VW_wL_sum'] = VW_data_mom.groupby('date')['VW_wL'].transform('sum')\n",
    "VW_data_mom['VW_wH'] = (VW_data_mom['leg'] == 1) * VW_data_mom['mcap']\n",
    "VW_data_mom['VW_wH_sum'] = VW_data_mom.groupby('date')['VW_wH'].transform('sum')\n",
    "VW_data_mom['VW_wL'] = VW_data_mom['VW_wL'] / VW_data_mom['VW_wL_sum']\n",
    "VW_data_mom['VW_wH'] = VW_data_mom['VW_wH'] / VW_data_mom['VW_wH_sum']\n",
    "VW_data_mom = VW_data_mom.drop(columns=['VW_wL_sum', 'VW_wH_sum'])\n",
    "VW_data_mom['VW_w'] = VW_data_mom['VW_wL'] * VW_data_mom['leg'] + VW_data_mom['VW_wH'] * VW_data_mom['leg']\n",
    "VW_data_mom['VW_ret'] = VW_data_mom['VW_w'] * VW_data_mom['ret']\n",
    "\n",
    "\n",
    "# Create a dataframe that aggregates the returns, at each month and keep the risk free rate\n",
    "VW_data_mom_ = VW_data_mom.groupby(['date']).agg({\n",
    "    'VW_ret': 'sum', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "# display(VW_data_mom_)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean = VW_data_mom_['VW_ret'].mean() * 12\n",
    "std = VW_data_mom_['VW_ret'].std() * np.sqrt(12)\n",
    "rf = VW_data_mom_[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on value weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}%\".format(mean))\n",
    "print(\" - Standard deviation:\\t {:.2f}%\".format(std))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean - rf)/ std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Idiosyncratic Volatility Strategy (IV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iv = data_Qb.drop(columns=['VW_weight', 'VW_ret_contrib', 'mcap_l', 'EW_monthly_decile']).copy()\n",
    "display(data_iv.head())\n",
    "print(data_iv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use previously computed rolling betas to compute the residuals of the regression of the stock's excess return against market excess return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è Je suis pas sur que ce soit la bonne mani√®re puisque les betas sont calcul√©s sur une rolling window d√©j√†, mais on recalcule l'√©cart type des r√©sidus sur une rolling window (rolling de rolling??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Residuals\n",
    "data_iv['residuals'] = data_iv['Rn_e'] - (data_iv['beta'] * data_iv['Rm_e'])\n",
    "\n",
    "# Compute volatility of residuals (idiosyncratic volatility)\n",
    "data_iv['IV'] = data_iv.groupby('permno')['residuals'].rolling(window=w, min_periods=36).std().reset_index(level=0, drop=True)\n",
    "data_iv = data_iv.dropna(subset=['IV']).copy()\n",
    "\n",
    "# Winsorize at 5% and 95% (code from PS5)\n",
    "data_iv['IV'] = data_iv['IV'].clip(data_iv['IV'].quantile(0.05), data_iv['IV'].quantile(0.95))\n",
    "\n",
    "data_iv = data_iv.drop(columns=['residuals']) # no need that column anymore\n",
    "\n",
    "display(data_iv.head())\n",
    "print(data_iv.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles based on IV\n",
    "data_iv[\"IV_decile\"] = data_iv.groupby(\"date\")[\"IV\"].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns_IV = data_iv.groupby([\"date\", \"IV_decile\"]).agg({\n",
    "    'date': 'first',\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'IV_decile': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'IV_decile': 'decile'})\n",
    "\n",
    "print(colored(\"Equally weighted monthly returns per decile, IV:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(EW_returns_IV.head(5))\n",
    "print(EW_returns_IV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Value weighted returns per month, for each decile\n",
    "data_iv['VW_weight'] = data_iv.groupby(['date', 'IV_decile'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_iv['VW_ret_contrib'] = data_iv['VW_weight'] * data_iv['ret']\n",
    "\n",
    "VW_returns_IV = data_iv.groupby([\"date\", \"IV_decile\"]).agg({\n",
    "    'date': 'first',\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'IV_decile': 'first',\n",
    "    }).reset_index(drop=True).rename(columns={'IV_decile': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(colored(\"Value weighted monthly returns per decile, IV:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(VW_returns_IV.head(5))\n",
    "print(VW_returns_IV.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean, std, sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns_IV, '5b', \"EW_returns_IV\")\n",
    "plot_mean_std_sr(VW_returns_IV, '5b', \"VW_returns_IV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column 'leg' that is 1 if the decile is 7, 8 or 9, and -1 if decile is 0, 1, 2\n",
    "data_iv['leg'] = np.nan\n",
    "data_iv.loc[data_iv['IV_decile'] <= 2, 'leg'] = -1\n",
    "data_iv.loc[data_iv['IV_decile'] >= 7, 'leg'] = 1\n",
    "\n",
    "# Drop the observations that are in none of the legs\n",
    "data_iv_c = data_iv.dropna().copy()\n",
    "\n",
    "display(data_iv_c.head())\n",
    "print(data_iv_c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compare the performance of each leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the performance of each leg\n",
    "EW_returns_IV_legs = data_iv_c.groupby([\"date\", \"leg\"]).agg({\n",
    "    'date': 'first',\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'leg': 'first'\n",
    "    }).reset_index(drop=True)\n",
    "\n",
    "testons = EW_returns_IV_legs.groupby('leg').agg({\n",
    "    'ret': 'std',\n",
    "    RF_COL: 'mean'\n",
    "    }).reset_index()\n",
    "display(testons)\n",
    "\n",
    "print(colored(\"Equally weighted monthly returns per leg, IV:\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\"Leg =  1 if decile is 7, 8, 9 \\nLeg = -1 if decile is 0, 1, 2\")\n",
    "display(EW_returns_IV_legs.head(5))\n",
    "print(EW_returns_IV_legs.shape)\n",
    "\n",
    "# Plot the mean, std, sr\n",
    "plot_mean_std_sr(EW_returns_IV_legs.rename(columns={'leg': 'decile'}), '5c', \"EW_returns_IV_legs\")\n",
    "print(\"In the graph, leg '-1' corresponds to bar '0'; leg '1' is bar '1'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second, display the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that aggregates takes the average return for each leg, at each month. Also keep the risk free rate\n",
    "EW_data_IV_leg = data_iv_c.groupby(['date', 'leg']).agg({\n",
    "    'ret': 'mean', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "EW_data_IV_piv = EW_data_IV_leg.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "EW_data_IV_piv['EW_return'] = EW_data_IV_piv[1] - EW_data_IV_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "EW_data_IV_piv[RF_COL] = EW_data_IV_leg.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "EW_data_IV_piv = EW_data_IV_piv[['EW_return', RF_COL]]   # Keep only the relevant columns\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean_EW_IV = EW_data_IV_piv['EW_return'].mean() * 12\n",
    "std_EW_IV = EW_data_IV_piv['EW_return'].std() * np.sqrt(12)\n",
    "rf_EW_IV = EW_data_IV_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on equally weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}\".format(mean_EW_IV))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(std_EW_IV))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean_EW_IV - rf_EW_IV)/ std_EW_IV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the 2 legs and the strategy in a graph\n",
    "mean, std, sr = get_mean_std_sharpe(EW_returns_IV_legs.rename(columns={'leg': 'decile'}))\n",
    "mean.append(mean_EW_IV), std.append(std_EW_IV), sr.append((mean_EW_IV - rf_EW_IV)/ std_EW_IV)\n",
    "# print(mean, std, sr)\n",
    "\n",
    "plot = plot_from_lists(mean, std, sr, plot_color = 'blue')\n",
    "\n",
    "plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio (EW_IV_legs_strat)')\n",
    "plot.savefig(f\"Figures/question_5c_plot_EW_IV_legs_strat\")\n",
    "plot.show()\n",
    "print(\"Bar 0: leg -1; Bar 1: leg 1; Bar 2: Strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, compare the performance of each leg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-use the dataframe from earlier question, we already computed the VW contribution\n",
    "VW_data_IV = data_iv_c.copy()\n",
    "\n",
    "VW_returns_IV_legs = VW_data_IV.groupby(['date', 'leg']).agg({\n",
    "    'VW_ret_contrib': 'sum', \n",
    "    RF_COL: 'first',\n",
    "    }).rename(columns={'VW_ret_contrib': 'ret'}).reset_index()\n",
    "\n",
    "display(VW_returns_IV_legs)\n",
    "\n",
    "# Plot the mean, std, sr\n",
    "plot_mean_std_sr(VW_returns_IV_legs.rename(columns={'leg': 'decile'}), '5c', \"VW_returns_IV_legs\")\n",
    "print(\"In the graph, leg '-1' corresponds to bar '0'; leg '1' is bar '1'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the same methodolgy as before to compute the return of the strategy\n",
    "VW_data_IV_piv = VW_returns_IV_legs.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "VW_data_IV_piv['VW_return'] = VW_data_IV_piv[1] - VW_data_IV_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "VW_data_IV_piv[RF_COL] = VW_data_IV_leg.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "VW_data_IV_piv = VW_data_IV_piv[['VW_return', RF_COL]]   # Keep only the relevant columns\n",
    "display(VW_data_IV_piv)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean_VW_IV = VW_data_IV_piv['VW_return'].mean() * 12\n",
    "std_VW_IV = VW_data_IV_piv['VW_return'].std() * np.sqrt(12)\n",
    "rf_VW_IV = VW_data_IV_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on value weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}\".format(mean_VW_IV))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(std_VW_IV))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean_VW_IV - rf_VW_IV)/ std_VW_IV))\n",
    "\n",
    "# Compare the 2 legs and the strategy in a graph\n",
    "mean, std, sr = get_mean_std_sharpe(VW_returns_IV_legs.rename(columns={'leg': 'decile'}))\n",
    "mean.append(mean_VW_IV), std.append(std_VW_IV), sr.append((mean_VW_IV - rf_VW_IV)/ std_VW_IV)\n",
    "# print(mean, std, sr)\n",
    "\n",
    "plot = plot_from_lists(mean, std, sr, plot_color = 'blue')\n",
    "\n",
    "plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio (VW_IV_legs_strat)')\n",
    "plot.savefig(f\"Figures/question_5c_plot_VW_IV_legs_strat\")\n",
    "plot.show()\n",
    "print(\"Bar 0: leg -1; Bar 1: leg 1; Bar 2: Strategy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Optimal Fund Portfolio Return (STRAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only consider the value weighted portfolios from the previous strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOL_TARGET = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we prepare the data\n",
    "dataBAB = data_BAB[['date', 'rBAB']].copy()\n",
    "dataMOM = VW_data_mom_[['date', 'VW_ret', RF_COL]].rename(columns={'VW_ret':'rMOM'}).copy()\n",
    "dataIV = VW_data_IV_piv.rename(columns={'VW_return':'rIV'}).copy().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data\n",
    "dataSTRAT = pd.merge(dataBAB, dataMOM, on='date', how='inner')\n",
    "dataSTRAT = pd.merge(dataSTRAT, dataIV[['date', 'rIV']], on='date', how='inner')\n",
    "dataSTRAT= dataSTRAT[['date', RF_COL, 'rBAB', 'rMOM', 'rIV']]\n",
    "display(dataSTRAT.head())\n",
    "print(dataSTRAT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the mean, std and Sharpe ratio of the STRAT strategies\n",
    "def get_mean_std_sharpe_STRAT(data, return_col:str):\n",
    "    mean = data[return_col].mean() * 12\n",
    "    std = data[return_col].std() * np.sqrt(12)\n",
    "    rf = data[RF_COL].mean() * 12\n",
    "    sr = (mean - rf) / std\n",
    "    return mean, std, sr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equal weight strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return of STRAT is the the weighted average of the returns of the 3 strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the STRAT return\n",
    "dataSTRAT_EW = dataSTRAT.copy()\n",
    "dataSTRAT_EW['rSTRAT_EW'] = (dataSTRAT_EW['rBAB'] + dataSTRAT_EW['rMOM'] + dataSTRAT_EW['rIV']) / 3\n",
    "dataSTRAT_EW.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#¬†Determining the c constant for each year\n",
    "dataSTRAT_EW['rSTRATstd'] = dataSTRAT_EW.groupby(dataSTRAT_EW.date.dt.year)['rSTRAT_EW'].transform('std') * np.sqrt(12)\n",
    "dataSTRAT_EW['C'] = 0.1 / dataSTRAT_EW['rSTRATstd']\n",
    "dataSTRAT_EW['rFUND_EW'] = dataSTRAT_EW['C'] * dataSTRAT_EW['rSTRAT_EW'] + dataSTRAT_EW[RF_COL]\n",
    "\n",
    "display(dataSTRAT_EW.head())\n",
    "print(dataSTRAT_EW.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retSTRAT_EW, stdSTRAT_EW, srSTRAT_EW = get_mean_std_sharpe_STRAT(dataSTRAT_EW, 'rFUND_EW')\n",
    "\n",
    "print(colored(\"STRAT strategy based on equally weighted portfolios\", attrs=['underline', 'bold'])) \n",
    "print(\" - Expected return:\\t {:.2f}\".format(retSTRAT_EW))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(stdSTRAT_EW))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format(srSTRAT_EW))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk-parity based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We determine the weights of BAB, MOM, IV under a risk parity approach, based on the rolling estimate of their return std over the last 36 months (excluding last)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the risk parity, we use the rolling 3-year monthly volatility\n",
    "dataSTRAT_RP = dataSTRAT.copy()\n",
    "\n",
    "dataSTRAT_RP['rBABstd'] = dataSTRAT_RP['rBAB'].rolling(window=36, min_periods=36, closed='left').std() * np.sqrt(12)\n",
    "dataSTRAT_RP['rMOMstd'] = dataSTRAT_RP['rMOM'].rolling(window=36, min_periods=36, closed='left').std() * np.sqrt(12)\n",
    "dataSTRAT_RP['rIVstd'] = dataSTRAT_RP['rIV'].rolling(window=36, min_periods=36, closed='left').std()   * np.sqrt(12)\n",
    "dataSTRAT_RP.dropna(inplace=True)\n",
    "\n",
    "dataSTRAT_RP['rSTRAT'] = dataSTRAT_RP['rBAB']/dataSTRAT_RP['rBABstd'] + dataSTRAT_RP['rMOM']/dataSTRAT_RP['rMOMstd'] + dataSTRAT_RP['rIV']/dataSTRAT_RP['rIVstd']\n",
    "\n",
    "dataSTRAT_RP['rSTRATstd'] = dataSTRAT_RP.groupby(dataSTRAT_RP.date.dt.year)['rSTRAT'].transform('std') * np.sqrt(12)\n",
    "dataSTRAT_RP['C'] = 0.1 / dataSTRAT_RP['rSTRATstd']\n",
    "dataSTRAT_RP['rFUND_EW'] = dataSTRAT_RP['C'] * dataSTRAT_RP['rSTRAT'] + dataSTRAT_RP[RF_COL]\n",
    "\n",
    "retSTRAT_RP, stdSTRAT_RP, srSTRAT_RP = get_mean_std_sharpe_STRAT(dataSTRAT_RP, 'rFUND_EW')\n",
    "\n",
    "print(colored(\"STRAT strategy based on equally risk parity portfolios\", attrs=['underline', 'bold'])) \n",
    "print(\" - Expected return:\\t {:.2f}\".format(retSTRAT_RP))\n",
    "print(\" - Standard deviation:\\t {:.2f}\".format(stdSTRAT_RP))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format(srSTRAT_RP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
