{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Data_handler import Data, RF_COL\n",
    "from termcolor import colored\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "Data_instance = Data()               # create instance of the class Data()\n",
    "data = Data_instance.get_data()      # store the data of Data_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['permno','date'],inplace=True)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Betting Against Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('date').first().sort_values(by='date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stocks with less than 36 months of observation (code from PS5)\n",
    "# data['N'] = data.groupby(['permno'])['date'].transform('count')\n",
    "# data = data[data['N']>36].copy()\n",
    "\n",
    "# Add excess returns\n",
    "data['Rn_e'] = data['ret'] - data[RF_COL]\n",
    "data['Rm_e'] = data['vwretd'] - data[RF_COL]\n",
    "\n",
    "# Drop nan values\n",
    "data = data.dropna().copy()\n",
    "\n",
    "# Rolling betas for each stock, based on 5-year windows (code from PS5)\n",
    "w = 5 * 12  # window size\n",
    "covariance = data.set_index('date').groupby('permno')[['Rn_e', 'Rm_e']].rolling(window=w, min_periods=36).cov()\n",
    "betas = covariance.iloc[1::2,1].droplevel(2) / covariance.iloc[0::2,1].droplevel(2)\n",
    "betas = betas.dropna().reset_index().rename(columns={'Rm_e': 'beta'})\n",
    "\n",
    "# Make sure the dates columns are datetime\n",
    "betas.date = pd.to_datetime(betas.date)\n",
    "data.date = pd.to_datetime(data.date)\n",
    "\n",
    "# Offset the dates of the betas by 1 month (code from PS5)\n",
    "betas.date = betas.date + pd.DateOffset(months=1)\n",
    "\n",
    "# Merge the full data with betas (code from PS5)\n",
    "data_Qb = pd.merge(data, betas, on=['permno', 'date'], how='left')\n",
    "\n",
    "# Finally, we winsorize the betas (5% and 95%) (code from PS5)\n",
    "data_Qb['beta'] = data_Qb['beta'].clip(data_Qb['beta'].quantile(0.05), data_Qb['beta'].quantile(0.95))\n",
    "\n",
    "# Drop all nan\n",
    "data_Qb = data_Qb.dropna().copy()\n",
    "\n",
    "print('Distribution of betas:')\n",
    "print(data_Qb['beta'].describe(), '\\n')\n",
    "\n",
    "\n",
    "display(data_Qb.head()) # Overview of the data\n",
    "print(data_Qb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_Qb = data.copy().dropna() # Uncomment if decide to use the class method to get the rolling betas, which gives different results ðŸ˜ƒ\n",
    "print(\"Initial number of observations: \", data.shape[0])\n",
    "print(\"Final number of observations: \\t\", data_Qb.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles based on Beta value (code from PS5)\n",
    "data_Qb[\"EW_monthly_decile\"] = data_Qb.groupby(\"date\")[\"beta\"].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns = data_Qb.groupby([\"date\", \"EW_monthly_decile\"]).agg({\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'EW_monthly_decile': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'EW_monthly_decile': 'decile'})\n",
    "\n",
    "print(\"Equally weighted returns per month, for each decile:\")\n",
    "display(EW_returns.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_Qb['VW_weight'] = data_Qb.groupby(['date', 'EW_monthly_decile'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_Qb['VW_ret_contrib'] = data_Qb['VW_weight'] * data_Qb['ret']\n",
    "\n",
    "VW_returns = data_Qb.groupby([\"date\", \"EW_monthly_decile\"]).agg({\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'EW_monthly_decile': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'EW_monthly_decile': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(\"Value weighted returns per month, for each decile:\")\n",
    "display(VW_returns.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the mean returns, volatility, and sharpe ratios for EW and VW portfolios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auxiliary functions for plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std_sharpe(data):\n",
    "    \"\"\"Compute the annulalized mean, standard deviation and Sharpe ratio for each decile.\"\"\"\n",
    "    mean = list(map(lambda x: 12*x, data.groupby('decile')['ret'].mean().values.tolist()))\n",
    "    std = list(map(lambda x: np.sqrt(12)*x, data.groupby('decile')['ret'].std().values.tolist()))\n",
    "    rf = np.mean(list(map(lambda x: 12*x, data.groupby('decile')[RF_COL].mean().values.tolist())))\n",
    "    sr = list(map(lambda ret, vol: (ret - rf) / vol, mean, std))\n",
    "    \n",
    "    return mean, std, sr\n",
    "\n",
    "def plot_from_lists(mean, std, sharpe, plot_color = 'blue'):\n",
    "    deciles = list(range(len(mean)))\n",
    "\n",
    "    _, axs = plt.subplots(1, 3, figsize=(25, 7), sharey=False)\n",
    "\n",
    "    axs[0].bar(deciles, mean, color=plot_color)\n",
    "    axs[0].set_title(\"Average portolio mean return\")\n",
    "    axs[0].set_xticks(deciles)\n",
    "    axs[0].set_xlabel(\"Decile\")\n",
    "    axs[0].set_ylabel(\"Annualized return\")\n",
    "\n",
    "    axs[1].bar(deciles, std, color=plot_color)\n",
    "    axs[1].set_title(\"Average portolio annualized standard deviation\")\n",
    "    axs[1].set_xticks(deciles)\n",
    "    axs[1].set_xlabel(\"Decile\")\n",
    "    axs[1].set_ylabel(\"Annualized standard deviation\")\n",
    "\n",
    "    axs[2].bar(deciles, sharpe, color=plot_color)\n",
    "    axs[2].set_title(\"Average portolio annualized sharpe ratio\")\n",
    "    axs[2].set_xticks(deciles)\n",
    "    axs[2].set_xlabel(\"Decile\")\n",
    "    axs[2].set_ylabel(\"Annualized sharpe ratio\")\n",
    "    \n",
    "    return plt\n",
    "\n",
    "def plot_mean_std_sr(data, question, plot_name, show = True):\n",
    "    \"\"\"Takes a dataframe in input and returns a 3 graphs for the  annualized mean, std and sharpe ratio for some deciles.\"\"\"\n",
    "\n",
    "    if not os.path.exists(\"Figures\"):\n",
    "            os.makedirs(\"Figures\")\n",
    "    \n",
    "    mean, std, sharpe = get_mean_std_sharpe(data)\n",
    "\n",
    "    plot = plot_from_lists(mean, std, sharpe, plot_color = 'blue')\n",
    "\n",
    "    plot.suptitle(f'Average portolio annualized mean return, standard deviation and sharpe ratio ({plot_name})')\n",
    "    plot.savefig(f\"Figures/question_{question}_plot_{plot_name}\")\n",
    "\n",
    "    if show: \n",
    "        plot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns, '3b', \"EW_returns_bab\")\n",
    "plot_mean_std_sr(VW_returns, '3b', \"VW_returns_bab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question c) and d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Built the function for determining BAB weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bab_weights(data):\n",
    "    \"\"\"Computes the weights of the Betting-Against-Beta portfolio (code inspired from PS5).\"\"\"\n",
    "    df = data.copy()\n",
    "    df['z'] = df.groupby('date')['beta'].rank()                     # Assign each beta a rank, for each month\n",
    "    df['z_mean'] = df.groupby('date')['z'].transform('mean')        # Calculate the monthly mean the rank\n",
    "    df['norm'] = np.abs(df['z']- df['z_mean'])                      # Compute abs distance of rank to mean rank\n",
    "    df['sum_norm'] = df.groupby('date')['norm'].transform(\"sum\")    # Sum the distance\n",
    "    df['k'] = 2 / df['sum_norm']                                    # Compute the k\n",
    "\n",
    "    # Compute the BAB weights\n",
    "    df['wH'] = df['k'] * np.maximum(0, df['z'] - df['z_mean'])\n",
    "    df['wL'] = - df['k'] * np.minimum(0, df['z'] - df['z_mean'])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df = df.drop(columns=[\"z_mean\", 'z', 'norm', 'sum_norm', 'k'])\n",
    "\n",
    "    # Compute the weighted betas\n",
    "    df['bH'] = df['wH'] * df['beta']\n",
    "    df['bL'] = df['wL'] * df['beta']\n",
    "\n",
    "    # Compute the individual excess returns of the portfolios H and L\n",
    "    df['rH_e'] = df['wH'] * (df['ret'] - df[RF_COL])\n",
    "    df['rL_e'] = df['wL'] * (df['ret'] - df[RF_COL]) # Check that crazy formula bby ðŸ˜ƒ  (en gros, c'est okay de faire weight * excess return au lieu de faire weight * excess return?)\n",
    "    \n",
    "    # Compute the return and betas of the two portfolios for each period\n",
    "    df_ = df.groupby('date').agg({\n",
    "        'rH_e': 'sum',\n",
    "        'rL_e': 'sum',\n",
    "        'bH': 'sum',\n",
    "        'bL': 'sum',\n",
    "        'Rm_e': 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "    # Finally create the BAB portfolio return\n",
    "    df_['rBAB'] = df_['rL_e'] / df_['bL'] - df_['rH_e'] / df_['bH']\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the weights rBAB\n",
    "data_BAB = get_bab_weights(data_Qb)\n",
    "display(data_BAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the return, std and sharpe ratio of the BAB strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the rf based on question b) results, as the underlying data is the same\n",
    "rf = np.mean(list(map(lambda x: 12*x, VW_returns.groupby('decile')[RF_COL].mean().values.tolist())))\n",
    "\n",
    "# Compute the return, std and Sharpe ratio of the BAB strategy\n",
    "BAB_ret = data_BAB.rBAB.mean() * 12\n",
    "BAB_std = data_BAB.rBAB.std() * np.sqrt(12)\n",
    "BAB_shr = (BAB_ret - rf) / BAB_std\n",
    "\n",
    "# Compute the CAPM alpha\n",
    "data_BAB['one'] = 1 # Create the column for the constant\n",
    "model = sm.OLS(data_BAB['rBAB'], data_BAB[['one', 'Rm_e']]).fit() # Fit CAPM\n",
    "\n",
    "print(colored(\"Betting-against-beta strategy\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Mean return: {:.2f}\".format(BAB_ret))\n",
    "print(\" - Standard deviation: {:.2f}\".format(BAB_std))\n",
    "print(\" - Sharpe ratio: {:.2f}\".format(BAB_shr))\n",
    "print(\" - CAPM alpha: {:.2f}\".format(model.params.iloc[0] * 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Momentum Strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the deciles based on the 12-month cumulative return, excluding short term reversal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=['permno', 'date'], inplace=True)\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by permno, then date\n",
    "data_mom = data.copy()\n",
    "data_mom.sort_values(by=['permno', 'date'], inplace=True)\n",
    "\n",
    "# Add a column for momentum return (last 12 months, excluding last month)\n",
    "data_mom['roll_ret'] = data_mom.groupby('permno').ret.transform(lambda x: x.rolling(11, closed='left').sum())\n",
    "display(data_mom.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create deciles for the momentum returns\n",
    "data_mom['decile_mom'] = data_mom.groupby('date')['roll_ret'].transform(lambda x: pd.qcut(x, 10, labels=False, duplicates='drop'))\n",
    "\n",
    "# Compute the monthly return for each decile (this is the average of the individual monthly return of each stock from each decile)\n",
    "data_mom['EW_monthly_return'] = data_mom.groupby(['date', 'decile_mom'])['ret'].transform('mean')\n",
    "\n",
    "# Drop nan values\n",
    "data_mom = data_mom.dropna().copy()\n",
    "\n",
    "display(data_mom.head())\n",
    "print(data_mom.shape)\n",
    "# data_mom.to_csv('data_mom.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equally weighted returns per month, for each decile\n",
    "EW_returns_mom = data_mom.groupby(['date', 'decile_mom']).agg({\n",
    "    'ret': 'mean',\n",
    "    RF_COL: 'first',\n",
    "    'decile_mom': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'decile_mom': 'decile'})\n",
    "\n",
    "print(colored(\"Equally weighted returns per month, for each decile:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(EW_returns_mom.head(5))\n",
    "print(EW_returns_mom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value weighted returns per month, for each decile\n",
    "data_mom['VW_weight'] = data_mom.groupby(['date', 'decile_mom'])['mcap'].transform(lambda x: x / x.sum())\n",
    "data_mom['VW_ret_contrib'] = data_mom['VW_weight'] * data_mom['ret']\n",
    "\n",
    "VW_returns_mom = data_mom.groupby([\"date\", \"decile_mom\"]).agg({\n",
    "    'VW_ret_contrib': 'sum',\n",
    "    RF_COL: 'first',\n",
    "    'decile_mom': 'first',\n",
    "    'date': 'first'\n",
    "    }).reset_index(drop=True).rename(columns={'decile_mom': 'decile', 'VW_ret_contrib': 'ret'})\n",
    "\n",
    "print(colored(\"Value weighted returns per month, for each decile:\", \"black\", attrs=['underline', 'bold']))\n",
    "display(VW_returns_mom.head(5))\n",
    "print(VW_returns_mom.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the 2 different weightings\n",
    "plot_mean_std_sr(EW_returns_mom, '4a', \"EW_returns_mom\")\n",
    "plot_mean_std_sr(VW_returns_mom, '4a', \"VW_returns_mom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column 'leg' that is 1 if the decile is 7, 8 or 9, and -1 if decile is 0, 1, 2\n",
    "data_mom['leg'] = np.nan\n",
    "data_mom.loc[data_mom['decile_mom'] <= 2, 'leg'] = -1\n",
    "data_mom.loc[data_mom['decile_mom'] >= 7, 'leg'] = 1\n",
    "\n",
    "# Drop the observations that are in none of the legs\n",
    "data_mom_b = data_mom.dropna().copy()\n",
    "display(data_mom_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equally weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe that aggregates takes the average return for each leg, at each month. Also keep the risk free rate\n",
    "EW_data_mom = data_mom_b.groupby(['date', 'leg']).agg({\n",
    "    'ret': 'mean', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "EW_data_mom_piv = EW_data_mom.pivot(index='date', columns='leg', values='ret') # Pivot the data\n",
    "EW_data_mom_piv['EW_return'] = EW_data_mom_piv[1] - EW_data_mom_piv[-1] # Compute the return of the EW momentum strategy as being the difference between the two legs\n",
    "EW_data_mom_piv[RF_COL] = EW_data_mom.groupby('date')[RF_COL].first() # Add the risk free rate\n",
    "EW_data_mom_piv = EW_data_mom_piv[['EW_return', RF_COL]]   # Keep only the relevant columns\n",
    "#Â display(EW_data_mom_piv)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean = EW_data_mom_piv['EW_return'].mean() * 12\n",
    "std = EW_data_mom_piv['EW_return'].std() * np.sqrt(12)\n",
    "rf = EW_data_mom_piv[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on equally weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}%\".format(mean))\n",
    "print(\" - Standard deviation:\\t {:.2f}%\".format(std))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean - rf)/ std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "source": [
    "###  Value weighted portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VW_data_mom = data_mom_b.copy()\n",
    "\n",
    "VW_data_mom['VW_wL'] = (VW_data_mom['leg'] == -1) * VW_data_mom['mcap']\n",
    "VW_data_mom['VW_wL_sum'] = VW_data_mom.groupby('date')['VW_wL'].transform('sum')\n",
    "VW_data_mom['VW_wH'] = (VW_data_mom['leg'] == 1) * VW_data_mom['mcap']\n",
    "VW_data_mom['VW_wH_sum'] = VW_data_mom.groupby('date')['VW_wH'].transform('sum')\n",
    "VW_data_mom['VW_wL'] = VW_data_mom['VW_wL'] / VW_data_mom['VW_wL_sum']\n",
    "VW_data_mom['VW_wH'] = VW_data_mom['VW_wH'] / VW_data_mom['VW_wH_sum']\n",
    "VW_data_mom = VW_data_mom.drop(columns=['VW_wL_sum', 'VW_wH_sum'])\n",
    "VW_data_mom['VW_w'] = VW_data_mom['VW_wL'] * VW_data_mom['leg'] + VW_data_mom['VW_wH'] * VW_data_mom['leg']\n",
    "VW_data_mom['VW_ret'] = VW_data_mom['VW_w'] * VW_data_mom['ret']\n",
    "\n",
    "\n",
    "# Create a dataframe that aggregates the returns, at each month and keep the risk free rate\n",
    "VW_data_mom_ = VW_data_mom.groupby(['date']).agg({\n",
    "    'VW_ret': 'sum', \n",
    "    RF_COL: 'first',\n",
    "    }).reset_index()\n",
    "\n",
    "# display(VW_data_mom_)\n",
    "\n",
    "# Compute mean, std and Sharpe ratio\n",
    "mean = VW_data_mom_['VW_ret'].mean() * 12\n",
    "std = VW_data_mom_['VW_ret'].std() * np.sqrt(12)\n",
    "rf = VW_data_mom_[RF_COL].mean() * 12\n",
    "\n",
    "# Dispay the results\n",
    "print(colored(\"Momentum strategy based on value weighted portfolios\", \"black\", attrs=['underline', 'bold']))\n",
    "print(\" - Expected return:\\t {:.2f}%\".format(mean))\n",
    "print(\" - Standard deviation:\\t {:.2f}%\".format(std))\n",
    "print(\" - Sharpe ratio:\\t {:.2f}\".format((mean - rf)/ std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
